**Resources for learning BERT:**

first you need to understand deep learning so we recommend deep learning specialization by Andrew Ng in coursera

  https://www.coursera.org/specializations/deep-learning?utm_source=deeplearningai&utm_medium=institutions&utm_campaign=WebsiteCoursesDLSTopButton

then you need to learn python and keras

  https://www.deeplearning.ai/tensorflow-in-practice/

after that you can start using this concepts in NLP

  https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearningai&utm_medium=institutions&utm_campaign=WebsiteCoursesNLPTopButton

now you are ready to face new achivements in language processing

  http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/

  http://jalammar.github.io/illustrated-transformer/

  http://jalammar.github.io/illustrated-bert/

**google colab codes**

how word2vec(english) works

https://colab.research.google.com/github/chainer-community/chainer-colab-notebook/blob/master/official_example_en/word2vec.ipynb

how BERT works

https://colab.research.google.com/drive/1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU?usp=sharing

how ELMO works

https://colab.research.google.com/drive/13f6dKakC-0yO6_DxqSqo0Kl41KMHT8A1?usp=sharing
